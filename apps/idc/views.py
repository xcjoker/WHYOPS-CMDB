import json
import math
import os
import time

from rest_framework import viewsets, status, generics
from rest_framework.exceptions import NotFound
from rest_framework.response import Response
from rest_framework.views import APIView

from apps.idc.models import IdcRegion, IdcServer
from .serializer import IdcRegionSerializer, GetIdcServerSerializer, IdcServerUpdateSerializer, IdcServerSerializer
import paramiko
import requests
import math
from datetime import datetime

GLOBAL_FUNCTION = ''  # ä¹Ÿå¯ä»¥ä¸åœ¨è¿™é‡Œå®šä¹‰ï¼Œåªæ˜¯ä¸ºäº†è®©äººæ›´æ¸…æ¥šåœ°çœ‹åˆ°å…¨å±€å˜é‡
GLOBAL_REGION = None
SOFT_DIR = r'D:\pycharm\oaback\apps\idc\soft'
# ã€æ³¨æ„ã€‘è¯·ä¿®æ”¹ä¸ºä½ å®é™…ä¸‹è½½çš„æ–‡ä»¶å
NODE_PKG_NAME = 'node_exporter-1.6.1.linux-amd64.tar.gz'
JSON_FILE_PATH = os.path.join(SOFT_DIR, 'node_exporter_targets.json')
PROMETHEUS_API_URL = "http://localhost:9090/api/v1/query"
CMDB_API_URL = "http://192.168.239.1:8000/idc/server/api/"


class IdcRegionView(viewsets.ModelViewSet):
    queryset = IdcRegion.objects.all()
    serializer_class = IdcRegionSerializer

    def create(self, request, *args, **kwargs):
        serializer = self.get_serializer(data=request.data)
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data, status=status.HTTP_201_CREATED)  # è¿”å›æˆåŠŸå“åº”
        else:
            detail = list(serializer.errors.values())[0][0]
            return Response({'detail': detail}, status=status.HTTP_400_BAD_REQUEST)  # è¿”å›400é”™è¯¯


class IdcServerView(APIView):
    def post(self, request):
        global GLOBAL_FUNCTION
        global GLOBAL_REGION

        # ---------------------------------------------------------
        # 1. åŸºç¡€æ ¡éªŒ
        # ---------------------------------------------------------
        serializer = IdcServerSerializer(data=request.data)
        if not serializer.is_valid():
            print("æ ¡éªŒå¤±è´¥å…·ä½“åŸå› :", serializer.errors)
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        validated_data = serializer.validated_data
        ip = validated_data['ip']
        password = validated_data['password']
        GLOBAL_FUNCTION = validated_data['function']
        address = validated_data['region']

        GLOBAL_REGION = IdcRegion.objects.filter(address=address).first()
        if not GLOBAL_REGION:
            return Response({'detail': 'åœ°åŸŸä¸å­˜åœ¨'}, status=status.HTTP_400_BAD_REQUEST)

        # ---------------------------------------------------------
        # 2. SSH éƒ¨ç½² Node Exporter (ä¿æŒä½ åŸæœ‰é€»è¾‘)
        # ---------------------------------------------------------
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        try:
            try:
                ssh.connect(hostname=ip, username='root', password=password, timeout=10)
            except Exception as e:
                return Response({'detail': f'SSHè¿æ¥å¤±è´¥: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)

            sftp = ssh.open_sftp()
            local_path = os.path.join(SOFT_DIR, NODE_PKG_NAME)
            remote_path = f'/tmp/{NODE_PKG_NAME}'

            try:
                sftp.put(local_path, remote_path)
                # ç›´æ¥å†™å…¥æœåŠ¡æ–‡ä»¶ï¼Œé˜²æ­¢ç¼©è¿›é—®é¢˜
                service_content = """[Unit]
    Description=Node Exporter
    After=network.target

    [Service]
    User=node_exporter
    Group=node_exporter
    Type=simple
    ExecStart=/usr/local/bin/node_exporter --collector.tcpstat --web.listen-address=:27683

    [Install]
    WantedBy=multi-user.target
    """
                with sftp.open('/etc/systemd/system/node_exporter.service', 'w') as f:
                    f.write(service_content)
            except Exception as e:
                return Response({'detail': f'æ–‡ä»¶ä¸Šä¼ /å†™å…¥å¤±è´¥: {str(e)}'},
                                status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            finally:
                sftp.close()

            # å®‰è£…å‘½ä»¤
            install_cmd = f"""
                    tar -xvf {remote_path} -C /tmp/ &&
                    mv /tmp/node_exporter-*/node_exporter /usr/local/bin/ &&
                    useradd -rs /bin/false node_exporter || true &&
                    systemctl daemon-reload &&
                    systemctl enable node_exporter &&
                    systemctl restart node_exporter
                """
            stdin, stdout, stderr = ssh.exec_command(install_cmd)
            exit_status = stdout.channel.recv_exit_status()
            if exit_status != 0:
                err_msg = stderr.read().decode()
                return Response({'detail': f'éƒ¨ç½²å¤±è´¥: {err_msg}'}, status=status.HTTP_400_BAD_REQUEST)

            # ---------------------------------------------------------
            # 3. æ›´æ–° Prometheus å‘ç°æ–‡ä»¶
            # ---------------------------------------------------------
            self.update_prometheus_target(ip, address)

        except Exception as e:
            return Response({'detail': f'éƒ¨ç½²è¿‡ç¨‹é”™è¯¯: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)
        finally:
            ssh.close()

        # ---------------------------------------------------------
        # 4. ã€æ–°å¢ã€‘ä» Prometheus è·å–æ•°æ®å¹¶ POST åˆ° CMDB
        # ---------------------------------------------------------
        try:
            # 4.1 ç­‰å¾…æ•°æ®å°±ç»ª (è½®è¯¢)
            print(f"[*] æ­£åœ¨ç­‰å¾… Prometheus æŠ“å– {ip} çš„æ•°æ®...")
            instance_name = f"{ip}:27683"
            if not self.wait_for_prometheus_data(instance_name):
                return Response({'detail': 'éƒ¨ç½²æˆåŠŸï¼Œä½†PrometheusæŠ“å–è¶…æ—¶ï¼Œè¯·ç¨åæ‰‹åŠ¨åŒæ­¥'},
                                status=status.HTTP_201_CREATED)

            # 4.2 æŸ¥è¯¢å¹¶æ ¼å¼åŒ–æ•°æ®
            print(f"[*] å¼€å§‹ä» Prometheus è·å– {ip} è¯¦ç»†ä¿¡æ¯")
            server_info = self.collect_server_info_from_prom(ip, instance_name)
            print(server_info)

            # 4.3 å‘é€ POST è¯·æ±‚
            print(f"[*] æ­£åœ¨ä¸ŠæŠ¥æ•°æ®åˆ°: {CMDB_API_URL}")
            # æ³¨æ„ï¼šinfo_get.py é‡Œæ˜¯ data=json.dumps(getdata)ï¼Œrequests é»˜è®¤ Content-Type ä¸æ˜¯ json
            headers = {'Content-Type': 'application/json'}
            res = requests.post(CMDB_API_URL, data=json.dumps(server_info), headers=headers)

            if res.status_code not in [200, 201]:
                return Response({'detail': 'éƒ¨ç½²æˆåŠŸï¼Œä½†CMDBä¸ŠæŠ¥å¤±è´¥'}, status=status.HTTP_201_CREATED)

        except Exception as e:
            print(f"[-] ä¿¡æ¯åŒæ­¥é˜¶æ®µå‡ºé”™: {e}")
            # å³ä½¿åŒæ­¥å¤±è´¥ï¼Œéƒ¨ç½²ä¹Ÿæ˜¯æˆåŠŸçš„ï¼Œæ‰€ä»¥è¿”å› 201ï¼Œä½†åœ¨ detail é‡Œæç¤º
            return Response({'detail': f'éƒ¨ç½²æˆåŠŸï¼Œä½†ä¿¡æ¯åŒæ­¥å‡ºé”™: {str(e)}'}, status=status.HTTP_201_CREATED)

        return Response({'detail': 'éƒ¨ç½²æˆåŠŸå¹¶å·²å®Œæˆä¿¡æ¯åŒæ­¥'}, status=status.HTTP_200_OK)

    # ================= è¾…åŠ©æ–¹æ³• =================

    def update_prometheus_target(self, ip, region):
        """æ›´æ–° JSON æ–‡ä»¶"""
        target_list = []
        if os.path.exists(JSON_FILE_PATH):
            with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:
                content = f.read()
                if content:
                    target_list = json.loads(content)

        new_target = f"{ip}:27683"
        for item in target_list:
            if new_target in item.get('targets', []):
                return

        target_list.append({
            "targets": [new_target],
            "labels": {"region": region, "env": "prod"}
        })

        with open(JSON_FILE_PATH, 'w', encoding='utf-8') as f:
            json.dump(target_list, f, indent=4)

    def wait_for_prometheus_data(self, instance, max_retries=10, sleep_time=3):
        """è½®è¯¢æ£€æŸ¥ Prometheus æ˜¯å¦å·²æœ‰è¯¥å®ä¾‹çš„ up æŒ‡æ ‡"""
        query = f'up{{instance="{instance}"}}'
        for i in range(max_retries):
            try:
                res = requests.get(PROMETHEUS_API_URL, params={'query': query})
                data = res.json()
                if data['status'] == 'success' and len(data['data']['result']) > 0:
                    # è¿˜è¦ç¡®ä¿å€¼ä¸º 1 (å¥åº·)
                    if int(data['data']['result'][0]['value'][1]) == 1:
                        return True
            except:
                pass
            time.sleep(sleep_time)
        return False

    def query_prom(self, query):
        """é€šç”¨æŸ¥è¯¢åŒ…è£…"""
        try:
            res = requests.get(PROMETHEUS_API_URL, params={'query': query})
            res_json = res.json()
            if res_json['status'] == 'success' and res_json['data']['result']:
                return res_json['data']['result']
        except Exception as e:
            print(f"Prometheus query error: {e}")
        return []

    def collect_server_info_from_prom(self, ip, instance):
        """
        ä¿®æ­£ç‰ˆï¼šæ•°æ®æ ¼å¼å·²å¯¹é½ IdcServer æ¨¡å‹
        """
        data = {}

        # 1. Hostname -> hostname
        # Model: hostname = models.CharField
        res = self.query_prom(f'node_uname_info{{instance="{instance}"}}')
        data['hostname'] = res[0]['metric'].get('nodename', 'unknown') if res else 'unknown'

        # 2. CPU -> cpu_count
        # Model: cpu_count = models.IntegerField
        res = self.query_prom(f'count(count(node_cpu_seconds_total{{instance="{instance}"}}) by (cpu))')
        data['cpu_count'] = int(res[0]['value'][1]) if res else 0

        # 3. Memory -> memory_count (æ³¨æ„å­—æ®µåä¿®æ”¹ï¼)
        # Model: memory_count = models.FloatField
        res = self.query_prom(f'node_memory_MemTotal_bytes{{instance="{instance}"}}')
        if res:
            gb = float(res[0]['value'][1]) / 1024 / 1024 / 1024
            # Model æ˜¯ FloatFieldï¼Œç›´æ¥ä¼  float å³å¯ï¼Œä¿ç•™2ä½å°æ•°
            data['memory_count'] = round(gb, 2)
        else:
            data['memory_count'] = 0.00

        # 4. Disk -> disk_count (æ³¨æ„å­—æ®µåä¿®æ”¹ï¼é€»è¾‘æ”¹ä¸ºæ±‚å’Œ)
        # Model: disk_count = models.IntegerField
        # PromQL: è·å–æ‰€æœ‰ ext4/xfs æ–‡ä»¶ç³»ç»Ÿçš„å¤§å°
        res = self.query_prom(f'node_filesystem_size_bytes{{instance="{instance}", fstype=~"ext4|xfs"}}')

        total_disk_gb = 0

        if res:
            for item in res:
                # è¿‡æ»¤æ‰ docker/kubelet ç­‰å¹²æ‰°æŒ‚è½½ç‚¹
                mountpoint = item['metric'].get('mountpoint', '')
                if '/docker/' in mountpoint or '/kubelet/' in mountpoint:
                    continue

                # ç´¯åŠ å¤§å°
                size_gb = float(item['value'][1]) / 1024 / 1024 / 1024
                total_disk_gb += size_gb

        # Model æ˜¯ IntegerFieldï¼Œæ‰€ä»¥å–æ•´
        data['disk_count'] = int(total_disk_gb)

        # 5. IP -> ip (Model é‡Œæœ‰è¿™ä¸ªå­—æ®µ)
        # æ—¢ç„¶æ˜¯æ›´æ–°æ“ä½œï¼Œä¸”ä½ å·²ç»æœ‰äº† IPï¼Œç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ IP å³å¯
        # é™¤éä½ æƒ³æ›´æ–°ä¸ºä» Prometheus æŸ¥åˆ°çš„ IPï¼ˆé€šå¸¸æ²¡å¿…è¦ï¼‰
        data['ip'] = ip

        return data

    def get(self, request):
        servers = IdcServer.objects.all()
        serializer = GetIdcServerSerializer(servers, many=True)
        return Response(serializer.data)

    def delete(self, request, pk):
        server = IdcServer.objects.get(id=pk)
        ip = server.ip

        if ip:
            target_to_remove = f"{ip}:27683"

            if os.path.exists(JSON_FILE_PATH):
                try:
                    with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    # å…ˆä»æ¯ä¸ªç»„çš„ targets åˆ—è¡¨ä¸­ç§»é™¤ IP
                    for group in data:
                        if 'targets' in group and target_to_remove in group['targets']:
                            group['targets'].remove(target_to_remove)

                    # è¿‡æ»¤æ‰é‚£äº› targets ä¸ºç©ºçš„åˆ†ç»„
                    # è¿™æ­¥æ“ä½œä¼šæŠŠ "targets": [] çš„æ•´ä¸ªå¯¹è±¡ï¼ˆåŒ…å« labelsï¼‰éƒ½åˆ æ‰
                    new_data = [group for group in data if len(group.get('targets', [])) > 0]

                    # 3. åªæœ‰æ•°æ®å‘ç”Ÿäº†å˜åŒ–ï¼ˆé•¿åº¦å˜äº†ï¼Œæˆ–è€…å†…å®¹å˜äº†ï¼‰æ‰å†™å›
                    if len(new_data) != len(data) or new_data != data:
                        with open(JSON_FILE_PATH, 'w', encoding='utf-8') as f:
                            json.dump(new_data, f, indent=4, ensure_ascii=False)
                        print(f"Prometheus é…ç½®å·²æ›´æ–°ï¼Œç§»é™¤äº†: {target_to_remove}")

                except Exception as e:
                    print(f"æ›´æ–° Prometheus æ–‡ä»¶å‡ºé”™: {e}")

        server.delete()
        return Response({'detail': 'åˆ é™¤æˆåŠŸ'}, status=status.HTTP_204_NO_CONTENT)


class IdcServerAPIView(APIView):

    def post(self, request):
        print('åˆ°æˆ‘è¿™é‡Œäº†')
        print(request.data)
        data = request.data
        hostname = data.get('hostname')
        cpu_count = data.get('cpu_count')
        mem_info = data.get('memory_count')
        disk_info = data.get('disk_count')
        ip_info = data.get('ip')
        server = IdcServer()
        server.scan_status = 2  # é»˜è®¤æ˜¯æ­£å¸¸ï¼Œåç»­å†åšåˆ¤æ–­
        server.hostname = hostname
        server.memory_count = mem_info
        server.disk_count = disk_info
        server.ip = ip_info
        server.function = GLOBAL_FUNCTION
        server.region = GLOBAL_REGION
        server.cpu_count = cpu_count
        server.save()
        print(hostname, cpu_count, mem_info, disk_info, ip_info, GLOBAL_FUNCTION, GLOBAL_REGION.username)

        return Response({'detail': 'success'}, status=status.HTTP_201_CREATED)


class IdcServerUpdateView(generics.RetrieveUpdateAPIView):
    queryset = IdcServer.objects.all()
    serializer_class = IdcServerUpdateSerializer


class IdcServerMonitor(APIView):
    def post(self, request):
        # 1. è·å–å‰ç«¯ä¼ æ¥çš„åŸå§‹æ•°æ®
        data = request.data
        raw_ip = data.get('ip')

        # ğŸ•µï¸â€â™‚ï¸ å¼ºåŠ›æ¸…æ´—ï¼šå¦‚æœå–å‡ºæ¥è¿˜æ˜¯ä¸ªå­—å…¸ï¼Œå°±å†å–ä¸€æ¬¡ (å…¼å®¹å‰ç«¯ä¸åŒä¼ å‚æ–¹å¼)
        if isinstance(raw_ip, dict):
            ip = raw_ip.get('ip')
        else:
            ip = raw_ip
        print('ipæ˜¯', ip)
        # 2. å®‰å…¨çš„æ—¶é—´å¤„ç†
        try:
            now = int(time.time())
            # æ³¨æ„ï¼šè¿™é‡Œå…¼å®¹ä½ çš„å‰ç«¯ç»“æ„ data['ip']['start_time']
            # å¦‚æœå‰ç«¯ä¼ çš„æ˜¯æ‰å¹³ç»“æ„ï¼Œéœ€è‡ªè¡Œè°ƒæ•´ï¼Œä½†ä¿ç•™ä½ ä¹‹å‰çš„å†™æ³•ä¼˜å…ˆ
            if isinstance(raw_ip, dict):
                start_time = int(raw_ip.get('start_time') or (now - 3600))
                end_time = int(raw_ip.get('end_time') or now)
                step_str = raw_ip.get('step', '60s')
            else:
                # å…œåº•é€»è¾‘
                start_time = int(data.get('start_time') or (now - 3600))
                end_time = int(data.get('end_time') or now)
                step_str = data.get('step', '60s')

        except (ValueError, TypeError, KeyError):
            return Response({"error": "Invalid timestamp format or data structure"}, status=400)

        # =======================================================
        # ğŸ›¡ï¸ æ ¸å¿ƒä»£ç ï¼šæ­¥é•¿è‡ªåŠ¨å¸é™„ä¸è­¦å‘Šç”Ÿæˆ
        # =======================================================

        # å…è®¸çš„å›ºå®šæ¡£ä½
        allowed_grids = [1, 10, 30, 60]

        # A. è®¡ç®—å®‰å…¨åº•çº¿ (Prometheus é™åˆ¶ 11000 ç‚¹ï¼Œæˆ‘ä»¬è®¾ 10000)
        duration = end_time - start_time
        min_safe_step = math.ceil(duration / 10000) if duration > 0 else 1
        print('æœ€å°æ­¥æ•°', min_safe_step)

        # B. è§£æç”¨æˆ·è¯·æ±‚çš„æ­¥é•¿
        try:
            current_step = int(str(step_str).replace('s', ''))
        except:
            current_step = 60  # è§£æå¤±è´¥å…œåº•

        # C. å®šä¹‰è­¦å‘Šæ¶ˆæ¯å˜é‡
        adjustment_msg = None
        step = step_str  # é»˜è®¤ä½¿ç”¨ç”¨æˆ·çš„

        # D. åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´
        if current_step < min_safe_step:
            # ç­–ç•¥ï¼šä»å…è®¸æ¡£ä½ä¸­æ‰¾ä¸€ä¸ª "åˆšå¥½ >= å®‰å…¨åº•çº¿" çš„å€¼
            new_step = min_safe_step  # é»˜è®¤å…ˆç”¨è®¡ç®—å€¼
            found_in_grid = False

            for grid in allowed_grids:
                if grid >= min_safe_step:
                    new_step = grid
                    found_in_grid = True
                    break

            # ç”Ÿæˆæœ€ç»ˆæ­¥é•¿å­—ç¬¦ä¸²
            step = f"{new_step}s"

            # â­â­â­ ç”Ÿæˆè­¦å‘Šæ¶ˆæ¯ï¼Œå‡†å¤‡è¿”å›ç»™å‰ç«¯
            # å¦‚æœè¿ 60s éƒ½ä¸å¤Ÿç”¨ (min_safe_step > 60)ï¼Œè¯´æ˜æŸ¥çš„æ—¶é—´å¤ªé•¿äº†
            if not found_in_grid:
                adjustment_msg = f"æŸ¥è¯¢èŒƒå›´è¿‡å¤§({duration // 3600}h)ï¼Œæ­¥é•¿å¼ºåˆ¶è°ƒæ•´ä¸º {new_step}s ä»¥é˜²æ­¢ç³»ç»Ÿå´©æºƒ"
            else:
                adjustment_msg = f"æ­¥é•¿è‡ªåŠ¨ä¼˜åŒ–: ç”³è¯·{current_step}s -> å®å‘{new_step}s (æ•°æ®é‡è¿‡å¤§ä¿æŠ¤)"

            print('æ–°æ­¥é•¿', step)
            print(f"DEBUG: {adjustment_msg}")

        instance_pattern = ip

        queries = {
            "cpu_usage": f'100 - (avg by(instance) (irate(node_cpu_seconds_total{{instance=~"{instance_pattern}",mode="idle"}}[5m])) * 100)',
            "mem_usage": f'(1 - (node_memory_MemAvailable_bytes{{instance=~"{instance_pattern}"}} / node_memory_MemTotal_bytes{{instance=~"{instance_pattern}"}})) * 100',
            "fs_usage_root": f'100 - (node_filesystem_avail_bytes{{instance=~"{instance_pattern}",mountpoint="/"}} / node_filesystem_size_bytes{{instance=~"{instance_pattern}",mountpoint="/"}} * 100)',
            "load_1": f'node_load1{{instance=~"{instance_pattern}"}}',
            "load_5": f'node_load5{{instance=~"{instance_pattern}"}}',
            "load_15": f'node_load15{{instance=~"{instance_pattern}"}}',
            "disk_io_read": f'sum by(instance) (irate(node_disk_read_bytes_total{{instance=~"{instance_pattern}"}}[5m])) / 1024 / 1024',
            "disk_io_write": f'sum by(instance) (irate(node_disk_written_bytes_total{{instance=~"{instance_pattern}"}}[5m])) / 1024 / 1024',
            "net_in": f'sum by(instance) (irate(node_network_receive_bytes_total{{instance=~"{instance_pattern}",device!="lo"}}[5m])) / 1024',
            "net_out": f'sum by(instance) (irate(node_network_transmit_bytes_total{{instance=~"{instance_pattern}",device!="lo"}}[5m])) / 1024',
            "tcp_established": f'node_tcp_connection_states{{instance=~"{instance_pattern}", state="established"}}',
            "tcp_syn_recv": f'node_tcp_connection_states{{instance=~"{instance_pattern}", state="syn_recv"}}',
            "tcp_time_wait": f'node_tcp_connection_states{{instance=~"{instance_pattern}", state="time_wait"}}',
            "tcp_close_wait": f'node_tcp_connection_states{{instance=~"{instance_pattern}", state="close_wait"}}',
            "tcp_listen": f'node_tcp_connection_states{{instance=~"{instance_pattern}", state="listen"}}'
        }

        results = {}

        if adjustment_msg:
            results['sys_warning'] = adjustment_msg

        # =======================================================
        # å¾ªç¯è¯·æ±‚ Prometheus
        # =======================================================
        for key, promql in queries.items():
            try:
                response = requests.get(
                    "http://localhost:9090/api/v1/query_range",
                    params={
                        "query": promql,
                        "start": start_time,
                        "end": end_time,
                        "step": step
                    },
                    timeout=30  # å¢åŠ è¶…æ—¶æ—¶é—´
                )

                if response.status_code != 200:
                    try:
                        err_msg = response.json().get('error', response.text)
                    except:
                        err_msg = response.text
                    print(f"Prometheus Error [{key}]: {err_msg}")
                    results[key] = {"times": [], "data": [], "error": err_msg}
                    continue

                data = response.json().get('data', {}).get('result', [])

                if data:
                    values = data[0].get('values', [])
                    results[key] = {
                        "times": [v[0] * 1000 for v in values],
                        "data": [round(float(v[1]), 2) if v[1] not in ["NaN", "+Inf", "-Inf"] else 0 for v in values]
                    }
                else:
                    results[key] = {"times": [], "data": []}

            except Exception as e:
                print(f"Exception querying {key}: {str(e)}")
                results[key] = {"times": [], "data": [], "error": f"Internal Error: {str(e)}"}

        return Response(results)
